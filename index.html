<!doctype html><html><head><meta name=generator content="Hugo 0.104.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>boxmein | Home</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta property="og:image" content><link rel=alternate type=application/rss+xml href=https://boxmein.github.io/index.xml title=boxmein><meta property="og:title" content="boxmein"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://boxmein.github.io/"><meta name=twitter:card content="summary"><meta name=twitter:title content="boxmein"><meta name=twitter:description content><link href=https://boxmein.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://boxmein.github.io/css/main.ac08a4c9714baa859217f92f051deb58df2938ec352b506df655005dcaf98cc0.css><script src=https://boxmein.github.io/posthog-tag.js></script></head><body><div class=content><header><div class=main><a href=https://boxmein.github.io/>boxmein</a></div><nav></nav></header><main class=list><div class=site-description></div><section class=list-item><h1 class=title><a href=/posts/2018-11-03-tartu-ctf-2018-writeup/>Tartu CTF 2018 - Writeup</a></h1><time>Nov 3, 2018</time><br><div class=description>I participated in a cybersecurity contest called a CTF (for capture the flag). It&rsquo;s a format of a security game where contestants have to attack a web or other type of server, and to prove their progress in breaking the server, they submit text strings called &ldquo;flags&rdquo; found at various steps of progress.
In the Tartu CTF 2018, we were playing the Game of Thrones CTF. At the start of the contest, we were given an IP address and nothing else.&mldr;</div><a class=readmore href=/posts/2018-11-03-tartu-ctf-2018-writeup/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2018-09-02-hack-the-box-poison-writeup/>Hack The Box: Poison - Writeup</a></h1><time>Sep 2, 2018</time><br><div class=description>NOTE: we did that in CyberCamp 2018. Just re-solving it. IP: 10.10.10.84
nmap Scanning 10.10.10.84 [65536 ports] Discovered open port 80/tcp on 10.10.10.84 Discovered open port 22/tcp on 10.10.10.84
Web server Web server has a bunch of &ldquo;testing PHP scripts&rdquo;.
One of the scripts is called listfiles.php, which lists the folder.
Among the PHP files there&rsquo;s also a file called pwdbackup.txt:
This password is secure, it's encoded atleast 13 times.. what could go wrong really.&mldr;</div><a class=readmore href=/posts/2018-09-02-hack-the-box-poison-writeup/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2017-09-30-path-planning-trajectory-generation-in-c/>Path Planning &amp;amp; Trajectory Generation in C++</a></h1><time>Sep 30, 2017</time><br><div class=description>This is a writeup of the Self-Driving Car Engineer Nanodegree Term 3 Path Planning project. It was very challenging to say the least, but with the approach presented in the walkthrough, I quickly made headway. It also outlined important implementation details such as working relative to the end of the path instead of the car, and reusing path points from previous iterations of the simulator.
Check out my source code.&mldr;</div><a class=readmore href=/posts/2017-09-30-path-planning-trajectory-generation-in-c/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2017-08-19-unscented-kalman-filters/>Unscented Kalman Filters</a></h1><time>Aug 19, 2017</time><br><div class=description>This post is about the Unscented Kalman Filters project. Unscented Kalman Filters are like a Level 2 version of Extended Kalman Filters.
When my code (hopefully) passes review, I&rsquo;ve finished Term 2 of the Nanodegree. (I&rsquo;ve been pushing forward for 7 months even though it feels like I just applied to enter the Nanodegree!)
Here&rsquo;s a video of the Unscented Kalman Filter doing what it&rsquo;s supposed to.
The red and blue dots are noisy sensor data, while the green dots are the Kalman filter deciding the car is somewhere in the middle of the sensor data.&mldr;</div><a class=readmore href=/posts/2017-08-19-unscented-kalman-filters/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2017-08-06-using-pid-to-drive-like-vin-diesel/>Using PID to drive like Vin Diesel</a></h1><time>Aug 6, 2017</time><br><div class=description>I just finished the PID controller project of the Udacity Self-Driving Car Nanodegree!
https://www.youtube.com/watch?v=SrdFTXpXkR4
The challenge was simple - make this car go around the track, when the simulator will tell you how far off you are.
To do this, especially since the simulator tells us an error metric, I needed to build a PID controller.
A PID controller is a simple function that relates the error (how off we are from our trajectory) to a control variable (throttle/steering/&mldr;).&mldr;</div><a class=readmore href=/posts/2017-08-06-using-pid-to-drive-like-vin-diesel/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2017-07-29-using-particle-filters-to-localize-a-car-in-2d-space/>Using Particle Filters to localize a car in 2D space</a></h1><time>Jul 29, 2017</time><br><div class=description>This is a discussion on how I implemented and finished the Particle Filters project in the Udacity Self-Driving Car Engineer Nanodegree.
The challenge Given a map of the world (a bunch of landmarks), and the car drawing lines to all landmarks within range with noisy data, give the best assumption for the car&rsquo;s position in the world.
The process How I was going to solve it was with an approach called particle filters.&mldr;</div><a class=readmore href=/posts/2017-07-29-using-particle-filters-to-localize-a-car-in-2d-space/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2017-06-04-using-extended-kalman-filters-for-object-tracking/>Using Extended Kalman Filters for object tracking</a></h1><time>Jun 4, 2017</time><br><div class=description>This is a discussion of how I solved the Extended Kalman Filters project in the Udacity Self-Driving Car Engineer Nanodegree.
The problem Our car has two sensors: a lidar and a radar. Both can see a pedestrian. Based on the lidar and radar data (both a bit noisy), keep track of the pedestrian&rsquo;s position and velocity.
The solution Kalman filters offer a solution that can combine both lidar and radar data to complement each other, and a robust object-tracking model that also keeps track of the error margins.&mldr;</div><a class=readmore href=/posts/2017-06-04-using-extended-kalman-filters-for-object-tracking/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2017-04-28-writeup-vehicle-detection/>Writeup: Vehicle Detection</a></h1><time>Apr 28, 2017</time><br><div class=description>Vehicle Detection Project** This is a writeup for my Vehicle Detection project.
Goals The goals / steps of this project are the following:
Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. Note: for those first two steps don&rsquo;t forget to normalize your features and randomize a selection for training and testing.&mldr;</div><a class=readmore href=/posts/2017-04-28-writeup-vehicle-detection/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2017-04-21-writeup-advanced-lane-finding/>Writeup: Advanced Lane Finding</a></h1><time>Apr 21, 2017</time><br><div class=description>Advanced Lane Finding Project The goals / steps of this project are the following:
Compute the camera calibration matrix and distortion coefficients given a set of chessboard images. Apply a distortion correction to raw images. Use color transforms, gradients, etc., to create a thresholded binary image. Apply a perspective transform to rectify binary image (&ldquo;birds-eye view&rdquo;). Detect lane pixels and fit to find the lane boundary. Determine the curvature of the lane and vehicle position with respect to center.&mldr;</div><a class=readmore href=/posts/2017-04-21-writeup-advanced-lane-finding/>Read more ⟶</a></section><section class=list-item><h1 class=title><a href=/posts/2017-03-31-writeup-behavioral-cloning/>Writeup: Behavioral Cloning</a></h1><time>Mar 31, 2017</time><br><div class=description>This one-to-one copy of my writeup for Udacity follows the format in the writeup template, hopefully making the writeup more thorough and easier to grade. It follows a pretty strict format, but includes a lot of interesting content. Behavioral Cloning Project
The goals / steps of this project are the following:
Use the simulator to collect data of good driving behavior Build, a convolution neural network in Keras that predicts steering angles from images Train and validate the model with a training and validation set Test that the model successfully drives around track one without leaving the road Summarize the results with a written report Rubric Points Here I will consider the rubric points individually and describe how I addressed each point in my implementation.&mldr;</div><a class=readmore href=/posts/2017-03-31-writeup-behavioral-cloning/>Read more ⟶</a></section><ul class=pagination><span class="page-item page-prev"></span><span class="page-item page-next"><a href=/page/2/ class=page-link aria-label=Next><span aria-hidden=true>Next →</span></a></span></ul></main><footer><div style=display:flex></div><div class=footer-info>2022 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer></div></body></html>