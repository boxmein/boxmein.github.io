<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>carnd on boxmein</title><link>https://boxmein.github.io/categories/carnd/</link><description>Recent content in carnd on boxmein</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 30 Sep 2017 00:00:00 +0000</lastBuildDate><atom:link href="https://boxmein.github.io/categories/carnd/index.xml" rel="self" type="application/rss+xml"/><item><title>Path Planning &amp;amp; Trajectory Generation in C++</title><link>https://boxmein.github.io/posts/2017-09-30-path-planning-trajectory-generation-in-c/</link><pubDate>Sat, 30 Sep 2017 00:00:00 +0000</pubDate><guid>https://boxmein.github.io/posts/2017-09-30-path-planning-trajectory-generation-in-c/</guid><description>This is a writeup of the Self-Driving Car Engineer Nanodegree Term 3 Path Planning project. It was very challenging to say the least, but with the approach presented in the walkthrough, I quickly made headway. It also outlined important implementation details such as working relative to the end of the path instead of the car, and reusing path points from previous iterations of the simulator.
Check out my source code.</description></item><item><title>Unscented Kalman Filters</title><link>https://boxmein.github.io/posts/2017-08-19-unscented-kalman-filters/</link><pubDate>Sat, 19 Aug 2017 00:00:00 +0000</pubDate><guid>https://boxmein.github.io/posts/2017-08-19-unscented-kalman-filters/</guid><description>This post is about the Unscented Kalman Filters project. Unscented Kalman Filters are like a Level 2 version of Extended Kalman Filters.
When my code (hopefully) passes review, I&amp;rsquo;ve finished Term 2 of the Nanodegree. (I&amp;rsquo;ve been pushing forward for 7 months even though it feels like I just applied to enter the Nanodegree!)
Here&amp;rsquo;s a video of the Unscented Kalman Filter doing what it&amp;rsquo;s supposed to.
The red and blue dots are noisy sensor data, while the green dots are the Kalman filter deciding the car is somewhere in the middle of the sensor data.</description></item><item><title>Using PID to drive like Vin Diesel</title><link>https://boxmein.github.io/posts/2017-08-06-using-pid-to-drive-like-vin-diesel/</link><pubDate>Sun, 06 Aug 2017 00:00:00 +0000</pubDate><guid>https://boxmein.github.io/posts/2017-08-06-using-pid-to-drive-like-vin-diesel/</guid><description>I just finished the PID controller project of the Udacity Self-Driving Car Nanodegree!
https://www.youtube.com/watch?v=SrdFTXpXkR4
The challenge was simple - make this car go around the track, when the simulator will tell you how far off you are.
To do this, especially since the simulator tells us an error metric, I needed to build a PID controller.
A PID controller is a simple function that relates the error (how off we are from our trajectory) to a control variable (throttle/steering/&amp;hellip;).</description></item><item><title>Using Particle Filters to localize a car in 2D space</title><link>https://boxmein.github.io/posts/2017-07-29-using-particle-filters-to-localize-a-car-in-2d-space/</link><pubDate>Sat, 29 Jul 2017 00:00:00 +0000</pubDate><guid>https://boxmein.github.io/posts/2017-07-29-using-particle-filters-to-localize-a-car-in-2d-space/</guid><description>This is a discussion on how I implemented and finished the Particle Filters project in the Udacity Self-Driving Car Engineer Nanodegree.
The challenge Given a map of the world (a bunch of landmarks), and the car drawing lines to all landmarks within range with noisy data, give the best assumption for the car&amp;rsquo;s position in the world.
The process How I was going to solve it was with an approach called particle filters.</description></item><item><title>Using Extended Kalman Filters for object tracking</title><link>https://boxmein.github.io/posts/2017-06-04-using-extended-kalman-filters-for-object-tracking/</link><pubDate>Sun, 04 Jun 2017 00:00:00 +0000</pubDate><guid>https://boxmein.github.io/posts/2017-06-04-using-extended-kalman-filters-for-object-tracking/</guid><description>This is a discussion of how I solved the Extended Kalman Filters project in the Udacity Self-Driving Car Engineer Nanodegree.
The problem Our car has two sensors: a lidar and a radar. Both can see a pedestrian. Based on the lidar and radar data (both a bit noisy), keep track of the pedestrian&amp;rsquo;s position and velocity.
The solution Kalman filters offer a solution that can combine both lidar and radar data to complement each other, and a robust object-tracking model that also keeps track of the error margins.</description></item><item><title>SDCND: Lane Line Detection</title><link>https://boxmein.github.io/posts/2017-01-25-sdcnd-lane-line-detection/</link><pubDate>Wed, 25 Jan 2017 00:00:00 +0000</pubDate><guid>https://boxmein.github.io/posts/2017-01-25-sdcnd-lane-line-detection/</guid><description>The self-driving Car Engineer Nanodegree (I&amp;rsquo;ll just use SDCND from here) is a huge Udacity course about self-driving cars starting from vision ending with robotics. I applied in October, having an incredible opportunity to participate since Jan 19.
The first project of the SDCND is about lane line detection. This is a simple experiment in computer vision using straight line detection and averaging to detect the left and right lane separators.</description></item></channel></rss>